{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_Project (with good_bad year).ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TXUp1DgW4Wmb"},"source":["# COGS 108 - Final Project "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"V21jCVnC4Wmc"},"source":["# Overview"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mhEy0wos4Wmd"},"source":["*Fill in your overview here*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6iJJ1g394Wmd"},"source":["# Names\n","\n","- Jason Lee\n","- Laurent Lee\n","- Qingyang Xu\n","- Tianze Zhang\n","- Yue Jiao\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hkw1gC4w4Wme"},"source":["# Group Members IDs\n","\n","- A########\n","- A########\n","- A########\n","- A########\n","- A15626544"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"StoCj5ou4Wme"},"source":["# Research Question"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"V23d4pQL4Wmf"},"source":["How does change in GDP per capita correlate to people’s movie genre preferences in USA? \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UvWlknst4Wmf"},"source":["## Background and Prior Work"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RzeFalvz4Wmg"},"source":["Movies are not merely just entertainment, it could let us experience what we could not do in reality and rich emotions. Reports have shown that films could evoke emotions within us. It is evident that individuals have different movie genre preferences, and the preference could be affected by a lot of factors. For example, GDP per capita is a measure of economic strenth, which is related to people’s personal income. In this project, we aim to investigate the correlation between change in GDP per capita and people’s movie genre preferences. We want unbiased data and visualizations to demonstrate this correlation. \n","\n","References (include links):\n","- 1) https://www.scpr.org/news/2014/12/04/48457/what-watching-movies-can-tell-us-about-how-our-bra/ \n","- 2) https://www.thebalance.com/gdp-per-capita-formula-u-s-compared-to-highest-and-lowest-3305848"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T8OnOp984Wmg"},"source":["# Hypothesis\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QTnMgcef4Wmh"},"source":["Since GDP per capita is directly related to people’s incomes and lower income could cause people to be depressed, we suspect that when the GDP per capita of a certain time period is lower, people prefer to watch more relaxing movies such as comedies or romance, while when the GDP per capita of a certain time period is higher, people prefer to watch more thrilling movies such as horror or action. \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tWaEFmR84Wmh"},"source":["# Dataset(s)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bbiysT1c4Wmi"},"source":["- Dataset Name: movies_metadata.csv\n","- Link to the dataset: \n","- Number of observations:\n","\n","- Dataset Name: change_gdp.csv\n","- Link to the dataset:\n","- Number of observations:\n","\n","(Copy this information for each dataset)\n","- Dataset Name:\n","- Link to the dataset:\n","- Number of observations:\n","\n","1-2 sentences describing each dataset. \n","\n","If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xwTJQjD04Wmi"},"source":["# Setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_tRY2XTA4Wmj","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import requests\n","import bs4\n","from bs4 import BeautifulSoup"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y7Y8VUiv4Wml"},"source":["# Data Cleaning"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4UsnZd_d4Wmm"},"source":["Describe your data cleaning steps here."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LSfTklpr4Wmn","outputId":"9706715f-5f7e-4956-eb4f-360c8afff5da","executionInfo":{"status":"error","timestamp":1560383853088,"user_tz":420,"elapsed":426,"user":{"displayName":"Jason Lee","photoUrl":"","userId":"10899333319066143697"}},"colab":{"base_uri":"https://localhost:8080/","height":443}},"source":["# gdp data\n","## YOUR CODE HERE\n","## add change in gdp data\n","data = pd.read_csv('gdp.csv')\n","data.set_index('Country Name', inplace = True)\n","data = data.loc['United States', :]\n","data = data.dropna()\n","data = data.drop('Country Code')\n","data = data.drop('Indicator Code')\n","data = data.drop('Indicator Name')\n","\n","#rename the dataframe\n","gdp = pd.DataFrame(data)\n","gdp = gdp.reset_index()\n","gdp.columns = ['date','GDP per capita growth (annual %)']\n","# change the gdp to numeric \n","gdp[\"date\"] = pd.to_numeric(gdp[\"date\"])"],"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-87aa2a6ca41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdp.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Country Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'United States'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Country Code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'gdp.csv' does not exist: b'gdp.csv'"]}]},{"cell_type":"code","metadata":{"id":"el-vvXBR66PQ","colab_type":"code","colab":{}},"source":["gdp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EFSD5D8mWgov","colab":{}},"source":["#read in data from .csv\n","df_movies = pd.read_csv('movies_metadata.csv')\n","\n","#drop irrelevant columns\n","df_movies.drop(columns=['homepage', 'id', 'imdb_id', 'original_language', 'overview', 'spoken_languages', 'status', \n","                 'tagline', 'poster_path', 'production_countries', 'video', 'production_companies',\n","                 'adult', 'belongs_to_collection', 'original_title', 'budget', \n","                 'revenue', 'runtime', 'vote_average', 'vote_count'], inplace=True)\n","\n","#rename and move around columns\n","df_movies.columns = ['genres', 'popularity', 'date', 'title']\n","df_movies = df_movies[['title', 'date', 'genres', 'popularity']]\n","#df_movies"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8rmd27gRWgo0","colab":{}},"source":["#drop rows that do not have data for title or release date\n","df_movies.dropna(subset=['date', 'title'], inplace=True)\n","#df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qme-81IRWgo2","colab":{}},"source":["# Convert all inputs to strings and normalize them\n","def standardize_date_movie(long):\n","    string = str(long)\n","    string = string.strip()\n","    string = string[0:4]\n","    date = int(string)\n","   # if(date < 1960 or date > 2017):\n","  #      string = np.nan\n","    return string"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qGlOPZSJWgo4","colab":{}},"source":["# Apply standardization and drop any movies out of the date boundary\n","df_movies[\"date\"] = df_movies[\"date\"].apply(standardize_date_movie)\n","df_movies.dropna(inplace=True)\n","\n","#change it to numeric\n","df_movies[\"date\"] = pd.to_numeric(df_movies[\"date\"])\n","# change the popularity to numeric \n","df_movies[\"popularity\"] = pd.to_numeric(df_movies[\"popularity\"])\n","\n","#sort the columns\n","df_movies.sort_values(by=['date'], ascending=True, inplace = True)\n","\n","# take all movies from 1971 to 2017 and get rid of other ones\n","df_movies = df_movies.loc[(df_movies[\"date\"] > 1960) & (df_movies[\"date\"] < 2017)]\n","\n","#genres = df_movies['genres']\n","#drop empty genres\n","df_movies = df_movies[~df_movies['genres'].isin(['[]'])]\n","#set date as index\n","#df_movies.set_index('date', inplace=True)\n","\n","df_movies.head()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Shw9cJe0Wgo-","colab":{}},"source":["#funtion to generate new dataframe based on genre\n","def genre_df(string):\n","    df = pd.DataFrame(columns=['title', 'date','genres','popularity'])\n","    for index, row in df_movies.iterrows():\n","        if string in row['genres']:\n","            df.loc[len(df.index)] = df_movies.loc[index]\n","            \n","    df.drop('genres', axis=1, inplace=True)\n","    df = df.reset_index()\n","    df = df.drop(['title'], axis = 1)\n","    df = df.groupby(['date']).mean()\n","    df = df.drop('index', axis = 1)\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U2o1bRBTWgpA","colab":{}},"source":["#get the genres\n","drama = genre_df('Drama')\n","romance = genre_df('Romance')\n","comedy = genre_df('Comedy')\n","action = genre_df('Action')\n","thriller = genre_df('Thriller')\n","adventure = genre_df('Adventure')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rGtcXv9o66Pc","colab_type":"code","colab":{}},"source":["drama"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CTTcvNdqWgpB","colab":{}},"source":["# gdp data\n","## YOUR CODE HERE\n","## add change in gdp data\n","data = pd.read_csv('gdp.csv')\n","data.set_index('Country Name', inplace = True)\n","data = data.loc['United States', :]\n","data = data.dropna()\n","data = data.drop('Country Code')\n","data = data.drop('Indicator Code')\n","data = data.drop('Indicator Name')\n","\n","#rename the dataframe\n","change_gdp = pd.DataFrame(data)\n","change_gdp = change_gdp.reset_index()\n","change_gdp.columns = ['date','GDP per capita growth (annual %)']\n","# change the gdp to numeric \n","change_gdp[\"date\"] = pd.to_numeric(change_gdp[\"date\"])\n","change_gdp.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_672iWS4jV5M","colab":{}},"source":["drama.reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nwSYP7oAjV5O","colab":{}},"source":["def merge(df):\n","    df = df.reset_index()\n","    df = df.merge(gdp, how='inner')\n","    #df = df.drop('index', index = 1)\n","    return df\n","drama = merge(drama)\n","romance = merge(romance)\n","comedy = merge(comedy)\n","action = merge(action)\n","thriller = merge(thriller)\n","adventure = merge(adventure)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wXfZWsEcjV5Q","colab":{}},"source":["#drama.rename(columns={'index':'gdp'},inplace=True)\n","#drama\n","#romance\n","\n","# convert gdp data to float\n","drama['GDP per capita growth (annual %)'] = pd.to_numeric(change_gdp['GDP per capita growth (annual %)'])\n","romance['GDP per capita growth (annual %)'] = pd.to_numeric(change_gdp['GDP per capita growth (annual %)'])\n","comedy['GDP per capita growth (annual %)'] = pd.to_numeric(change_gdp['GDP per capita growth (annual %)'])\n","action['GDP per capita growth (annual %)'] = pd.to_numeric(change_gdp['GDP per capita growth (annual %)'])\n","thriller['GDP per capita growth (annual %)'] = pd.to_numeric(change_gdp['GDP per capita growth (annual %)'])\n","adventure['GDP per capita growth (annual %)'] = pd.to_numeric(change_gdp['GDP per capita growth (annual %)'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RFpoJk_ijV5S","colab":{}},"source":["# grpah all of them, and save to variable\n","drama_graph = drama.plot.scatter('popularity', 'GDP per capita growth (annual %)')\n","romance_graph = romance.plot.scatter('popularity', 'GDP per capita growth (annual %)')\n","comedy_graph = comedy.plot.scatter('popularity', 'GDP per capita growth (annual %)')\n","action_graph = drama.plot.scatter('popularity', 'GDP per capita growth (annual %)')\n","thriller_graph = romance.plot.scatter('popularity', 'GDP per capita growth (annual %)')\n","adventure_graph = comedy.plot.scatter('popularity', 'GDP per capita growth (annual %)')\n","\n","#set titles\n","drama_graph.set_title(\"Drama Graph\")\n","romance_graph.set_title(\"Romance Graph\")\n","comedy_graph.set_title(\"Comedy Graph\")\n","action_graph.set_title(\"Action Graph\")\n","thriller_graph.set_title(\"Thriller Graph\")\n","adventure_graph.set_title(\"Adventure Graph\")\n","drama_graph"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tuekYUb2jV5W","colab":{}},"source":["# corrlational analysis\n","Drama_corr = drama.corr()\n","Romance_corr = romance.corr()\n","Comedy_corr = comedy.corr()\n","Action_corr = action.corr()\n","Thriller_corr = thriller.corr()\n","Adventure_corr = adventure.corr()\n","\n","# put them in one dataframe\n","Genre_corr = pd.DataFrame()\n","Genre_corr.ignore_index = True\n","Genre_corr = Genre_corr.append(pd.DataFrame([Drama_corr[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr = Genre_corr.append(pd.DataFrame([Romance_corr[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr = Genre_corr.append(pd.DataFrame([Comedy_corr[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr = Genre_corr.append(pd.DataFrame([Action_corr[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr = Genre_corr.append(pd.DataFrame([Thriller_corr[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr = Genre_corr.append(pd.DataFrame([Adventure_corr[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","\n","Genre_corr.index = [0, 1, 2, 3, 4, 5]\n","Genre_corr.rename(index={0:\"Drama\", 1:\"Romance\", 2:\"Comedy\", 3:\"Action\", 4:\"Thriller\", 5:\"Adventure\" }, inplace=True)\n","Genre_corr"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4cy7X7XCjV5Y"},"source":["As the table above indicates, there is very little corrlation between GDP change and movie perference. Our group suspect that this may cause by the fluctation of GDP data: for example, a good fiscal yaer may 3% growth or 4% growth, but they are both good years. Therefore, out group further classify each years into good years and bad years, where good years have a higher GDP change than average and bad year have a lower GDP than average."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jdEgWcPZjV5Z","colab":{}},"source":["# calculate average GDP\n","average_gdp = drama[\"GDP per capita growth (annual %)\"].mean()\n","\n","# create a cloumn for each table with good/bad year classfication\n","# 1.0 means it is a good year\n","\n","classify_year = lambda gdp: 1.0 if gdp > average_gdp else 0.0\n","gdp_good_yaers = []\n","\n","for item in drama[\"GDP per capita growth (annual %)\"]:\n","    gdp_good_yaers.append(classify_year(item))\n","    \n","drama[\"good_years\"] = gdp_good_yaers\n","romance[\"good_years\"] = gdp_good_yaers\n","comedy[\"good_years\"] = gdp_good_yaers\n","action[\"good_years\"] = gdp_good_yaers\n","thriller[\"good_years\"] = gdp_good_yaers\n","adventure[\"good_years\"] = gdp_good_yaers\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FEBY51RLjV5b","colab":{}},"source":["# graph them\n","drama_graph_good_or_bad = drama[drama.good_years == 1.0]\\\n","     .plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='red', label='good year');\n","drama[drama.good_years == 0.0]\\\n",".plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='blue', label='bad year',\\\n","      ax = drama_graph_good_or_bad);\n","\n","romance_graph_good_or_bad = romance[romance.good_years == 1.0]\\\n","     .plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='red', label='good year');\n","romance[romance.good_years == 0.0]\\\n",".plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='blue', label='bad year',\\\n","      ax = romance_graph_good_or_bad);\n","\n","comedy_graph_good_or_bad = comedy[comedy.good_years == 1.0]\\\n","     .plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='red', label='good year');\n","comedy[comedy.good_years == 0.0]\\\n",".plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='blue', label='bad year',\\\n","      ax = comedy_graph_good_or_bad);\n","\n","action_graph_good_or_bad = action[action.good_years == 1.0]\\\n","     .plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='red', label='good year');\n","action[action.good_years == 0.0]\\\n",".plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='blue', label='bad year',\\\n","      ax = action_graph_good_or_bad);\n","\n","thriller_graph_good_or_bad = thriller[thriller.good_years == 1.0]\\\n","     .plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='red', label='good year');\n","thriller[thriller.good_years == 0.0]\\\n",".plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='blue', label='bad year',\\\n","      ax = thriller_graph_good_or_bad);\n","\n","adventure_graph_good_or_bad = adventure[adventure.good_years == 1.0]\\\n","     .plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='red', label='good year');\n","adventure[adventure.good_years == 0.0]\\\n",".plot(kind='scatter', y='popularity', x='GDP per capita growth (annual %)', color='blue', label='bad year',\\\n","      ax = adventure_graph_good_or_bad);\n","\n","#set titles\n","drama_graph_good_or_bad.set_title(\"Drama Graph (good vs bad years)\")\n","romance_graph_good_or_bad.set_title(\"Romance Graph (good vs bad years)\")\n","comedy_graph_good_or_bad.set_title(\"Comedy Graph (good vs bad years)\")\n","action_graph_good_or_bad.set_title(\"Action Graph (good vs bad years)\")\n","thriller_graph_good_or_bad.set_title(\"Thriller Graph (good vs bad years)\")\n","adventure_graph_good_or_bad.set_title(\"Adventure Graph (good vs bad years)\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bzsDFcrJjV5d","colab":{}},"source":["# calculate corrlation separatly for good years\n","Drama_corr_good_year = drama[drama.good_years == 1.0].corr()\n","Romance_corr_good_year = romance[romance.good_years == 1.0].corr()\n","Comedy_corr_good_year = comedy[comedy.good_years == 1.0].corr()\n","Action_corr_good_year = action[action.good_years == 1.0].corr()\n","Thriller_corr_good_year = thriller[thriller.good_years == 1.0].corr()\n","Adventure_corr_good_year = adventure[adventure.good_years == 1.0].corr()\n","\n","# put them in one dataframe\n","Genre_corr_good_years = pd.DataFrame()\n","Genre_corr_good_years.ignore_index = True\n","Genre_corr_good_years = Genre_corr_good_years.append(pd.DataFrame([Drama_corr_good_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_good_years = Genre_corr_good_years.append(pd.DataFrame([Romance_corr_good_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_good_years = Genre_corr_good_years.append(pd.DataFrame([Comedy_corr_good_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_good_years = Genre_corr_good_years.append(pd.DataFrame([Action_corr_good_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_good_years = Genre_corr_good_years.append(pd.DataFrame([Thriller_corr_good_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_good_years = Genre_corr_good_years.append(pd.DataFrame([Adventure_corr_good_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","\n","Genre_corr_good_years.index = [0, 1, 2, 3, 4, 5]\n","Genre_corr_good_years.rename(index={0:\"Drama\", 1:\"Romance\", 2:\"Comedy\", 3:\"Action\", 4:\"Thriller\", 5:\"Adventure\" }, inplace=True)\n","Genre_corr_good_years"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1Oj0Q8OljV5g","colab":{}},"source":["# calculate corrlation separatly for bad years\n","Drama_corr_bad_year = drama[drama.good_years == 0.0].corr()\n","Romance_corr_bad_year = romance[romance.good_years == 0.0].corr()\n","Comedy_corr_bad_year = comedy[comedy.good_years == 0.0].corr()\n","Action_corr_bad_year = action[action.good_years == 0.0].corr()\n","Thriller_corr_bad_year = thriller[thriller.good_years == 0.0].corr()\n","Adventure_corr_bad_year = adventure[adventure.good_years == 0.0].corr()\n","\n","# put them in one dataframe\n","Genre_corr_bad_years = pd.DataFrame()\n","Genre_corr_bad_years.ignore_index = True\n","Genre_corr_bad_years = Genre_corr_bad_years.append(pd.DataFrame([Drama_corr_bad_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_bad_years = Genre_corr_bad_years.append(pd.DataFrame([Romance_corr_bad_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_bad_years = Genre_corr_bad_years.append(pd.DataFrame([Comedy_corr_bad_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_bad_years = Genre_corr_bad_years.append(pd.DataFrame([Action_corr_bad_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_bad_years = Genre_corr_bad_years.append(pd.DataFrame([Thriller_corr_bad_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","Genre_corr_bad_years = Genre_corr_bad_years.append(pd.DataFrame([Adventure_corr_bad_year[\"popularity\"][\"GDP per capita growth (annual %)\"]]))\n","\n","Genre_corr_bad_years.index = [0, 1, 2, 3, 4, 5]\n","Genre_corr_bad_years.rename(index={0:\"Drama\", 1:\"Romance\", 2:\"Comedy\", 3:\"Action\", 4:\"Thriller\", 5:\"Adventure\" }, inplace=True)\n","Genre_corr_bad_years"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LvWswXtsjV5i","colab":{}},"source":["# test how much "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eHykv1Gv4Wmp"},"source":["# Data Analysis & Results"]},{"cell_type":"code","metadata":{"id":"u7p_CRkBGrGR","colab_type":"code","colab":{}},"source":["#merge relaxing genres and thrilling genres into their own dataframes\n","df_relaxing_merge = pd.concat([drama, comedy, romance])\n","df_thrilling_merge = pd.concat([action, adventure, thriller])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5gih9e5KjV5k","colab":{}},"source":["#OLS for relaxing movies\n","f0 = \"popularity ~ gdp\"\n","outcome_1, predictors_1 = patsy.dmatrices(f0, df_relaxing_merge, return_type = \"matrix\")\n","mod_1 = sm.OLS(outcome_1, predictors_1)\n","res_1 = mod_1.fit()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3CidwBS1HdUV","colab_type":"code","colab":{}},"source":["#OLS for thrilling movies\n","f0 = \"popularity ~ gdp\"\n","outcome_2, predictors_2 = patsy.dmatrices(f0, df_thrilling_merge, return_type = \"matrix\")\n","mod_2 = sm.OLS(outcome_2, predictors_2)\n","res_2 = mod_2.fit()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y0POc4yg4Wmp"},"source":["Include cells that describe the steps in your data analysis."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9yNaSBeH4Wmq","colab":{}},"source":["## YOUR CODE HERE\n","gdp.plot(use_index=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M7MTHEos4Wmu"},"source":["# Ethics & Privacy"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ADw5tJ4p4Wmv"},"source":["The movie sells data and GDP data may contain some personal information such as the name, age, sex, and income, especially when cross-matching with other data available online. We need to filter that unrelated and personal information before we work with the dataset. We will save all the data in the google drive and only the team members will have access to them. There could be analysis bias since \n","A. Data Collection\n"," A.1 Informed consent: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n"," A.2 Collection bias: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n"," A.3 Limit PII exposure: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n","B. Data Storage\n"," B.1 Data security: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n"," B.2 Right to be forgotten: Do we have a mechanism through which an individual can request their personal information be removed?\n"," B.3 Data retention plan: Is there a schedule or plan to delete the data after it is no longer needed?\n","C. Analysis\n"," C.1 Missing perspectives: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n"," C.2 Dataset bias: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n"," C.3 Honest representation: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n"," C.4 Privacy in analysis: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n"," C.5 Auditability: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n","D. Modeling\n"," D.1 Proxy discrimination: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n"," D.2 Fairness across groups: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n"," D.3 Metric selection: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n"," D.4 Explainability: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n"," D.5 Communicate bias: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n","E. Deployment\n"," E.1 Redress: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n"," E.2 Roll back: Is there a way to turn off or roll back the model in production if necessary?\n"," E.3 Concept drift: Do we test and monitor for concept drift to ensure the model remains fair over time?\n"," E.4 Unintended use: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vJWRsp7K4Wmv"},"source":["# Conclusion & Discussion"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ywXT6wjo4Wmw"},"source":["*Fill in your discussion information here*"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gZVi2-aF4Wmw","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQxO3H0HHbQ1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}